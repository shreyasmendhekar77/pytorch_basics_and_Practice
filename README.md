# ðŸ“š PyTorch Basics & Practice

A hands-on learning repository covering foundational to advanced PyTorch topics â€” including tensor operations, automatic differentiation, neural network creation (ANNs, CNNs, RNNs), hyperparameter tuning, autograd mechanics, and mathematical operations.

---

##  Repository Overview

This repository features Jupyter notebooks that explore key PyTorch functionalities:

- **Tensor Mathematics & Operations**  
- **Autograd & Gradient Computation**  
- **Model Building with `nn.Module`** (ANNs, CNNs, RNNs)  
- **Data Loading: `Dataset` & `DataLoader` in PyTorch**  
- **Training & Optimization** (Fashion-MNIST using ANN)  
- **CNN Model Implementation**  
- **Hyperparameter Tuning (Optuna)**  
- **Custom Autograd Functions**  
- Organized under notebooks such as:
  - `Basics_mathmatical_functions_Pytorch.ipynb`
  - `Pytorch_autograd.ipynb`
  - `model_building_using_NNmodule.ipynb`
  - `simple_ANN_Model_on_MNIST_Fashion_dataset.ipynb`
  - `CNN_model_using_Pytorch.ipynb`
  - `Hyperparameter_tuning_using_Optuna.ipynb`
  - `dataloaders_and_dataset_in_pytorch.ipynb`

---

##  Why This Repository?

- Learn PyTorch fundamental building blocks: tensors, fine-grained control via autograd, and core mathematical operations.
- Build and train neural networks across architectures â€” simple feedforward, convolutional, and recurrent models.
- Understand training workflows: data loading, model definition, optimization, and tuning.
- Gain hands-on experience with hyperparameter tuning using **Optuna**.
- Practice extending PyTorch via **custom autograd functions**.

---

##  Structure & Getting Started

```text
â”œâ”€â”€ Basics_mathmatical_functions_Pytorch.ipynb
â”œâ”€â”€ Pytorch_autograd.ipynb
â”œâ”€â”€ dataloaders_and_dataset_in_pytorch.ipynb
â”œâ”€â”€ model_building_using_NNmodule.ipynb
â”œâ”€â”€ simple_ANN_Model_on_MNIST_Fashion_dataset.ipynb
â”œâ”€â”€ CNN_model_using_Pytorch.ipynb
â”œâ”€â”€ Hyperparameter_tuning_using_Optuna.ipynb
â””â”€â”€ fmnist_small.csv
